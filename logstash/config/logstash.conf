input {
  # Configure your input plugin (e.g., file, stdin, etc.)
  # file {
  #   path => "/usr/share/logstash/myelkwebapi/logs/myelkwebapi-logs-*.log"   # Rolling file pattern
  #   start_position => "beginning"
  #   sincedb_path => "/dev/null" # Disable sincedb to re-read logs on restart
  #   tags => ["myelkwebapi"]
  # }
  # file {
  #   path => "/usr/share/logstash/product/logs/product-logs-*.csv"
  #   start_position => "beginning"
  #   sincedb_path => "/dev/null"
  #   tags => ["product_log"]
  # }
  # file {
  #   path => "/usr/share/logstash/myother/logs/test-*.log"
  #   start_position => "beginning"
  #   sincedb_path => "/dev/null"
  #   tags => ["other_log"]
  # }
  beats {
    port => 5044
  }
}
filter {
  # Optional: Add filter plugins to process events
   # Example: Add logic based on tags
  if [input][id] == "product" {
      csv {
        separator => ","
        columns => ["name","description","price","imageUrl","category"]
      }
      # date {
      #   match => [ "timestamp", "yyyy-MM-dd HH:mm:ss", "ISO8601" ]
      #   target => "@timestamp"
      #   remove_field => [ "timestamp" ]
      # }
  } 
  else if [input][id] == "myelkwebapi" {
      grok {
        match => { 
          "message" => "%{TIMESTAMP_ISO8601:log_timestamp} (?<tz>[-+]\d{2}:\d{2}) \[%{LOGLEVEL:level}\] %{GREEDYDATA:forecast_json}"
          }
      }
      # date {
      #   match => [ "log_timestamp", "yyyy-MM-dd HH:mm:ss.SSS" ]
      #   timezone => "America/New_York" # Adjust if needed
      #   target => "@timestamp"
      #   remove_field => [ "log_timestamp", "tz" ]
      # }
      json {
        source => "forecast_json"
        target => "forecast"
        # If you want each forecast as an array of objects
      }
      split {
        field => "forecast"
      }
      ruby {
      code => '
        if event.get("forecast").is_a?(Hash)
          event.get("forecast").each { |k,v| event.set(k, v) }
          event.remove("forecast")
        end
      '
      }
    }
   # Add more filters as needed
 }

output {
   if [input][id] == "myelkwebapi" {
    
    opensearch {
      hosts => ["https://opensearch-node1:9200", "https://opensearch-node2:9200"] # Point to the OpenSearch service name in docker-compose
      #hosts => ["https://localhost:9200"] # Point to the OpenSearch service name in docker-compose
      user => "admin"
      password => "StrongP@ssw0rd54321" # Use the admin password for OpenSearch
      index => "myelkwebapi-logs-%{+YYYYMMdd}" # Define the index name
      ssl => true
      cacert => "/usr/share/logstash/config/ca.pem"  
      ssl_certificate_verification => true # Adjust as needed based on your setup
    }
   }
   else if [input][id] == "product" {
    opensearch {
      hosts => ["https://opensearch-node1:9200", "https://opensearch-node2:9200"]
      user => "admin"
      password => "StrongP@ssw0rd54321"
      index => "product-logs-%{+YYYYMMdd}"
      ssl => true
      cacert => "/usr/share/logstash/config/ca.pem"
      ssl_certificate_verification => true
    }
   } 
   else if [input][id] == "other" {
    opensearch {
      hosts => ["https://opensearch-node1:9200", "https://opensearch-node2:9200"]
      user => "admin"
      password => "StrongP@ssw0rd54321"
      index => "other-%{+YYYYMMdd}"
      ssl => true
      cacert => "/usr/share/logstash/config/ca.pem"
      ssl_certificate_verification => true
      }
    stdout { codec => rubydebug }
  }
}
